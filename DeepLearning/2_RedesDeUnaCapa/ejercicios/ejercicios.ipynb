{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaxr86i2hnX-"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/DeepLearning/2_RedesDeUnaCapa/ejercicios/ejercicios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgsT9jksm5LF"
      },
      "source": [
        "# Ejercicios para la clase 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEwhMG1-wDZw"
      },
      "source": [
        "En este notebook vamos a retomar el ejemplo de la red neuronal entrenada para clasificar FashionMNIST. Si bien ese ejemplo tiene todos los pasos necesarios para entrenar la red, varios de esos pasos sirven para entrenar cualquier otro modelo. Así que vamos a tratar de modularizarlo de manera que el código sea reutilizable.\n",
        "\n",
        "Arranquemos importando los módulos necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IKoVRbjSfc6",
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from IPython import display\n",
        "from torchvision import transforms\n",
        "from torch.utils import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZRZy4UfRQhB"
      },
      "source": [
        "Volvemos a definir la función que crea los Datasets y devuelve los DataLoaders para poder iterar sobre ellos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wo108R04-B3"
      },
      "outputs": [],
      "source": [
        "def load_data_fashion_mnist(batch_size, resize=None):\n",
        "    trans = [transforms.ToTensor()]\n",
        "    if resize:\n",
        "        trans.insert(0, transforms.Resize(resize))\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(\n",
        "        root=\"../data\", train=True, transform=trans, download=True)\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(\n",
        "        root=\"../data\", train=False, transform=trans, download=True)\n",
        "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=1),\n",
        "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xbesO6LRS_G"
      },
      "source": [
        "También definimos una función que devuelve la cantidad de aciertos del modelo a partir de un tensor de predicciones y otro de etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrSYLgd4SfdP",
        "origin_pos": 27,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZkInvacReE4"
      },
      "source": [
        "Volvemos a definir el modelo con una capa de 10 neuronas para hacer la clasificación e inicializamos sus pesos aleatoriamente con una distribución gaussiana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBFL4_UxSYQc",
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(784, 10))\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == torch.nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "net.apply(init_weights);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKCx8gJfRiTc"
      },
      "source": [
        "Definimos la entropía cruzada como función de perdida y el descenso de gradiente estocástico como algoritmo de optimización. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlPHONcmSYQf",
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFeFfZzK0KIO"
      },
      "source": [
        "Y por último, definimos una función que lleva adelante el entrenamiento completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkWvYfcnyIw9"
      },
      "outputs": [],
      "source": [
        "def train(net, train_iter, test_iter, loss, num_epochs, updater):\n",
        "  '''\n",
        "  Lleva adelante el entrenamiento completo llamando a funciones internas\n",
        "  que modularizan el ciclo de entrenamiento.\n",
        "\n",
        "    Parámetros:\n",
        "            net: la red neuronal que se va a entrenar\n",
        "            train_iter: iterador de datos de entrenamiento\n",
        "            test_iter: iterador de datos de prueba\n",
        "            loss: función de perdida a minimizar\n",
        "            num_epoch: cantidad de épocas a entrenar\n",
        "            updater: algoritmo de optimización\n",
        "\n",
        "    Salida:\n",
        "            metrics: una lista de tuplas (una para cada epoch)\n",
        "              con las siguientes componentes\n",
        "              - epoch: número de época\n",
        "              - L: pérdida calculada\n",
        "              - Acc: accuracy de entrenamiento calculada\n",
        "              - TestAcc: accuracy de prueba calculada\n",
        "  '''\n",
        "  metrics =[]\n",
        "  for epoch in range(num_epochs):\n",
        "      L, Acc = train_epoch(net, train_iter, loss, updater)\n",
        "      TestAcc = test_accuracy(net, test_iter)\n",
        "      metric = (epoch + 1, L, Acc, TestAcc)\n",
        "      print(metric)\n",
        "      metrics.append(metric)\n",
        "  return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1rb67LYPG0o"
      },
      "source": [
        "## Ejercicio 1\n",
        "\n",
        "Implementar la función `train_epoch()` que lleva adelante el entrenamiento de una época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-j-GPHgzHhx"
      },
      "outputs": [],
      "source": [
        "def train_epoch(net, train_iter, loss, updater):\n",
        "  '''\n",
        "  Lleva adelante el entrenamiento de una sola época.\n",
        "\n",
        "    Parámetros:\n",
        "            net: la red neuronal que se va a entrenar\n",
        "            train_iter: iterador de datos de entrenamiento\n",
        "            loss: función de perdida a minimizar\n",
        "            updater: algoritmo de optimización\n",
        "\n",
        "    Salida:\n",
        "            L: pérdida calculada\n",
        "            Acc: accuracy de entrenamiento calculada\n",
        "  '''\n",
        "  # inserte su código aquí\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUDesTD05Ern"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Implementar la función `test_accuracy()` que lleva adelante la evaluación de la performance de la red con los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6FI7Ym-wFpS"
      },
      "outputs": [],
      "source": [
        "def test_accuracy(net, test_iter):\n",
        "  '''\n",
        "  Evalúa los resultados del entrenamiento de una sola época.\n",
        "\n",
        "    Parámetros:\n",
        "            net: la red neuronal que se va a evaluar\n",
        "            test_iter: iterador de datos de prueba\n",
        "\n",
        "    Salida:\n",
        "            - TestAcc: accuracy de prueba calculada\n",
        "  '''\n",
        "  # inserte su código aquí\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeLMq-kc6_EH"
      },
      "source": [
        "## Ejercicio 3\n",
        "\n",
        "Utilizar las funciones anteriores para entrenar efectivamente a la red. Entrenarla por 10 epochs y con lotes de tamaño 256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tD0w1U0R6xO"
      },
      "outputs": [],
      "source": [
        "#inserte su código aquí\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtyCl3ZyEyjL"
      },
      "source": [
        "## Ejercicio 4\n",
        "Graficar la evolución de los valores de el accuracy de entrenamiento, el accuracy de prueba y la pérdida en función de las épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MctBmcjbGwZ"
      },
      "outputs": [],
      "source": [
        "#inserte su código aquí\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Ejercicios.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
